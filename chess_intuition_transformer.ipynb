{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3c0c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: 3.5.0\n",
      "torch: 2.5.1\n",
      "numpy: 2.0.1\n",
      "tqdm: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "try: import datasets; print(f\"datasets: {datasets.__version__}\") \n",
    "except ImportError: print(\"datasets: Not installed.\") \n",
    "try: import torch; print(f\"torch: {torch.__version__}\") \n",
    "except ImportError: print(\"torch: Not installed.\") \n",
    "try: import numpy; print(f\"numpy: {numpy.__version__}\") \n",
    "except ImportError: print(\"numpy: Not installed.\") \n",
    "try: import tqdm; print(f\"tqdm: {tqdm.__version__}\") \n",
    "except ImportError: print(\"tqdm: Not installed.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1f35039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, DatasetDict, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import os\n",
    "import numpy as np\n",
    "# import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from preprocessing import add_representations, fen_to_piece_maps, fen_to_token_ids\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91a00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if DEVICE == torch.device(\"cpu\"):\n",
    "    print(\"Using CPU, not recommended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e585da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_fens = [example['fen'] for example in batch]\n",
    "    labels = torch.tensor(\n",
    "        [example['target'] for example in batch],\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    inputs = torch.stack([\n",
    "        torch.tensor(fen_to_token_ids(fen), dtype=torch.long)\n",
    "        for fen in batch_fens\n",
    "    ])\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e540892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk(os.path.join(os.getcwd(), \"processed_data/lichess_db_eval_10m/train\"))\n",
    "val_dataset = load_from_disk(os.path.join(os.getcwd(), \"processed_data/lichess_db_eval_10m/validation\"))\n",
    "test_dataset = load_from_disk(os.path.join(os.getcwd(), \"processed_data/lichess_db_eval_10m/test\"))\n",
    "\n",
    "num_training_examples = len(train_dataset)\n",
    "\n",
    "train_dataset = train_dataset.to_iterable_dataset(num_shards=32)\n",
    "val_dataset = val_dataset.to_iterable_dataset()\n",
    "test_dataset = test_dataset.to_iterable_dataset()\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=10000)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17fe26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d5f5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessEvalTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=31, d_model=128, n_heads=4, n_layers=8):      # vocab size is 31 because there are 12 piece tokens, 16 castling tokens, 2 side-to-move tokens + '0'\n",
    "        super().__init__()\n",
    "        seq_len = 64 + 1 + 1\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(seq_len, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, n_heads, dim_feedforward=d_model*4, dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, n_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(d_model//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 66)\n",
    "        B, L = x.size()\n",
    "\n",
    "        tok_emb = self.embed(x)                     # (B,66,d)\n",
    "        pos = torch.arange(L, device=DEVICE)\n",
    "        pos_emb = self.pos_embed(pos).unsqueeze(0)  # (1,66,d)\n",
    "\n",
    "        h = tok_emb + pos_emb                       # (B,66,d)\n",
    "        h = self.transformer(h.permute(1,0,2))      # (66,B,d)     - transformer expects (seq, batch, d)\n",
    "        h = h.mean(dim=0)                           # (B,d)\n",
    "        h = self.norm(h)\n",
    "\n",
    "        out = self.reg_head(h).squeeze(-1)          # (B,)\n",
    "        return torch.tanh(out)                      # in the range [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d4ef74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syeda\\miniconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 3\n",
    "total_iters = NUM_EPOCHS * ((10_000_000 // 256) + 1)\n",
    "\n",
    "model = ChessEvalTransformer().to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_iters, eta_min=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "steps, train_losses, train_maes, val_losses, val_maes = [], [], [], [], []       # for tracking performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 101it [00:12,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 — train_loss: 0.2395, train_mae: 0.3369, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 201it [00:27,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 — train_loss: 0.2295, train_mae: 0.3282, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 301it [00:43,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 — train_loss: 0.2245, train_mae: 0.3238, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 401it [00:58,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 — train_loss: 0.2229, train_mae: 0.3222, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 499it [01:13,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 — train_loss: 0.2209, train_mae: 0.3206, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 501it [02:01, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 500 — train_loss: 0.2209, train_mae: 0.3206, val_loss: 0.2162, val_mae: 0.3132\n",
      "Saved new best model after 500 iters\n",
      "--------Validation MAE improved to 0.313151--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 601it [02:16,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 — train_loss: 0.2210, train_mae: 0.3211, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 701it [02:33,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700 — train_loss: 0.2208, train_mae: 0.3213, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 801it [02:48,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800 — train_loss: 0.2204, train_mae: 0.3210, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 901it [03:05,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900 — train_loss: 0.2202, train_mae: 0.3208, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 915it [03:07,  4.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()   \n\u001b[1;32m---> 29\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m batch_mae \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(preds \u001b[38;5;241m-\u001b[39m labels))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     32\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_val_mae = float('inf')\n",
    "num_iterations = 0\n",
    "patience_counter = 0    # Count iterations without sufficient improvement\n",
    "PATIENCE = 15000        # How many iterations to wait, noting that total_iters is around 117k for 3 epochs and batch size of 256\n",
    "MIN_IMPROVEMENT = 5e-4  # Minimum improvement required for early stopping to not trigger\n",
    "VAL_ITERS = 5000\n",
    "LOG_ITERS = 1000\n",
    "\n",
    "early_stop = False\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_mae = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()   \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        batch_mae = torch.mean(torch.abs(preds - labels)).item()\n",
    "\n",
    "        total_loss += batch_loss * inputs.size(0)\n",
    "        total_mae += batch_mae * inputs.size(0)\n",
    "        num_iterations += 1\n",
    "\n",
    "        # Every 1000 steps, log training loss and MAE\n",
    "        if num_iterations % LOG_ITERS == 0:\n",
    "            avg_train_loss = total_loss / (num_iterations * train_loader.batch_size)\n",
    "            avg_train_mae = total_mae / (num_iterations * train_loader.batch_size)\n",
    "            print(f\"Step {num_iterations} — train_loss: {avg_train_loss:.4f}, train_mae: {avg_train_mae:.4f}\")\n",
    "\n",
    "        # Every 5000 steps, run validation and record performance\n",
    "        if num_iterations % VAL_ITERS == 0:\n",
    "            model.eval()\n",
    "            val_loss_sum = 0.0\n",
    "            val_mae_sum = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    val_inputs, val_labels = val_inputs.to(DEVICE), val_labels.to(DEVICE)\n",
    "                    val_pred = model(val_inputs)\n",
    "                    val_loss = criterion(val_pred, val_labels)\n",
    "                    val_mae = torch.mean(torch.abs(val_pred - val_labels))\n",
    "\n",
    "                    val_loss_sum += val_loss.item() * val_inputs.size(0)\n",
    "                    val_mae_sum += val_mae.item() * val_inputs.size(0)\n",
    "\n",
    "            avg_val_loss = val_loss_sum / 250_000\n",
    "            avg_val_mae = val_mae_sum / 250_000\n",
    "\n",
    "            print(f\"Validating! Step {num_iterations} — train_loss: {avg_train_loss:.4f}, train_mae: {avg_train_mae:.4f}, val_loss: {avg_val_loss:.4f}, val_mae: {avg_val_mae:.4f}, current_LR: {scheduler.get_last_lr()[0]:.4f}\")\n",
    "\n",
    "            steps.append(num_iterations)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            train_maes.append(avg_train_mae)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_maes.append(avg_val_mae)\n",
    "\n",
    "            # Checkpoint best\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"best_chess_transformer.pth\")\n",
    "                print(f\"Saved new best model after {num_iterations} iters\")\n",
    "            \n",
    "            # Check if validation MAE improved by 0.0005 at least\n",
    "            if avg_val_mae + MIN_IMPROVEMENT < best_val_mae:\n",
    "                best_val_mae = avg_val_mae\n",
    "                patience_counter = 0  # Reset patience\n",
    "                print(f\"--------Validation MAE improved to {best_val_mae:.6f}--------\")\n",
    "            else:\n",
    "                patience_counter += VAL_ITERS  # because we validate after every VAL_ITERS \n",
    "                print(f\"--------No significant MAE improvement for {patience_counter} iterations--------\")\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"Early stopping at {num_iterations} iterations (no significant MAE improvement)\")\n",
    "                early_stop = True\n",
    "                break\n",
    "\n",
    "            model.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcdce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss_sum = 0.0\n",
    "test_mae_sum = 0.0\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_inputs, test_labels = test_inputs.to(DEVICE), test_labels.to(DEVICE)\n",
    "        test_pred = model(test_inputs)\n",
    "        test_loss = criterion(test_pred, test_labels)\n",
    "        test_mae = torch.mean(torch.abs(test_pred - test_labels))\n",
    "\n",
    "        test_loss_sum += test_loss.item() * test_inputs.size(0)\n",
    "        test_mae_sum += test_mae.item() * test_inputs.size(0)\n",
    "\n",
    "avg_test_loss = test_loss_sum / 250_000\n",
    "avg_test_mae = test_mae_sum / 250_000\n",
    "\n",
    "print(f\"Test results: test_loss: {avg_test_loss:.4f}, test_mae: {avg_test_mae:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
