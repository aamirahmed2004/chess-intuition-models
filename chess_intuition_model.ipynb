{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1f35039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, DatasetDict, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import os\n",
    "import numpy as np\n",
    "# import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from preprocessing import add_representations, fen_to_piece_maps, fen_to_token_ids\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91a00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if DEVICE == torch.device(\"cpu\"):\n",
    "    print(\"Using CPU, not recommended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e585da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_fens = [example['fen'] for example in batch]\n",
    "    labels = torch.tensor(\n",
    "        [example['target'] for example in batch],\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    inputs = torch.stack([\n",
    "        torch.tensor(fen_to_token_ids(fen), dtype=torch.long)\n",
    "        for fen in batch_fens\n",
    "    ])\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e540892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk(os.path.join(os.getcwd(), \"processed_data/lichess_db_eval_10m/train\"))\n",
    "val_dataset = load_from_disk(os.path.join(os.getcwd(), \"processed_data/lichess_db_eval_10m/validation\"))\n",
    "test_dataset = load_from_disk(os.path.join(os.getcwd(), \"processed_data/lichess_db_eval_10m/test\"))\n",
    "\n",
    "num_training_examples = len(train_dataset)\n",
    "\n",
    "train_dataset = train_dataset.to_iterable_dataset(num_shards=32)\n",
    "val_dataset = val_dataset.to_iterable_dataset()\n",
    "test_dataset = test_dataset.to_iterable_dataset()\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=10000)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17fe26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessEvalTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=31, d_model=256, n_heads=8, n_layers=6):      # vocab size is 31 because there are 12 piece tokens, 16 castling tokens, 2 side-to-move tokens + '0'\n",
    "        super().__init__()\n",
    "        seq_len = 64 + 1 + 1\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(seq_len, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, n_heads, dim_feedforward=d_model*4, dropout=0.2\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, n_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(d_model//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 66)\n",
    "        B, L = x.size()\n",
    "\n",
    "        tok_emb = self.embed(x)                     # (B,66,d)\n",
    "        pos = torch.arange(L, device=DEVICE)\n",
    "        pos_emb = self.pos_embed(pos).unsqueeze(0)  # (1,66,d)\n",
    "\n",
    "        h = tok_emb + pos_emb                       # (B,66,d)\n",
    "        h = self.transformer(h.permute(1,0,2))      # (66,B,d)     - transformer expects (seq, batch, d)\n",
    "        h = h.mean(dim=0)                           # (B,d)\n",
    "        h = self.norm(h)\n",
    "\n",
    "        out = self.reg_head(h).squeeze(-1)          # (B,)\n",
    "        return torch.tanh(out)                      # in the range [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d4ef74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syeda\\miniconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 3\n",
    "total_iters = NUM_EPOCHS * ((10_000_000 // 256) + 1)\n",
    "\n",
    "model = ChessEvalTransformer().to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_iters, eta_min=5e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "steps, train_losses, train_maes, val_losses, val_maes = [], [], [], [], []       # for tracking performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 101it [00:10,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 — train_loss: 0.2339, train_mae: 0.3302, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 201it [00:21,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 — train_loss: 0.2264, train_mae: 0.3249, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 301it [00:34,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 — train_loss: 0.2223, train_mae: 0.3218, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 401it [00:46,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 — train_loss: 0.2213, train_mae: 0.3209, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 499it [00:59,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 — train_loss: 0.2196, train_mae: 0.3195, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 501it [01:39,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 500 — train_loss: 0.2196, train_mae: 0.3195, val_loss: 0.2162, val_mae: 0.3128\n",
      "Saved new best model after 500 iters\n",
      "--------Validation MAE improved to 0.312769--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 601it [01:53,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 — train_loss: 0.2200, train_mae: 0.3203, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 701it [02:08,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700 — train_loss: 0.2199, train_mae: 0.3206, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 801it [02:22,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800 — train_loss: 0.2196, train_mae: 0.3204, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 901it [02:36,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900 — train_loss: 0.2194, train_mae: 0.3203, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 999it [02:51,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 — train_loss: 0.2196, train_mae: 0.3204, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1001it [03:37,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 1000 — train_loss: 0.2196, train_mae: 0.3204, val_loss: 0.2160, val_mae: 0.3178\n",
      "Saved new best model after 1000 iters\n",
      "--------No significant MAE improvement for 500 iterations--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1101it [03:52,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1100 — train_loss: 0.2195, train_mae: 0.3202, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1201it [04:06,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1200 — train_loss: 0.2194, train_mae: 0.3200, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1301it [04:22,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1300 — train_loss: 0.2194, train_mae: 0.3201, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1401it [04:37,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1400 — train_loss: 0.2193, train_mae: 0.3202, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1499it [04:51,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1500 — train_loss: 0.2194, train_mae: 0.3203, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1501it [05:37,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 1500 — train_loss: 0.2194, train_mae: 0.3203, val_loss: 0.2162, val_mae: 0.3224\n",
      "--------No significant MAE improvement for 1000 iterations--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1601it [05:53,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600 — train_loss: 0.2195, train_mae: 0.3204, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1701it [06:09,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1700 — train_loss: 0.2193, train_mae: 0.3201, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1801it [06:24,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1800 — train_loss: 0.2193, train_mae: 0.3200, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1901it [06:38,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1900 — train_loss: 0.2190, train_mae: 0.3198, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1999it [06:52,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000 — train_loss: 0.2189, train_mae: 0.3197, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2001it [07:38,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 2000 — train_loss: 0.2189, train_mae: 0.3197, val_loss: 0.2163, val_mae: 0.3119\n",
      "--------Validation MAE improved to 0.311883--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2101it [07:50,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2100 — train_loss: 0.2187, train_mae: 0.3195, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2201it [08:03,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2200 — train_loss: 0.2187, train_mae: 0.3195, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2301it [08:18,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2300 — train_loss: 0.2188, train_mae: 0.3196, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2401it [08:32,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2400 — train_loss: 0.2189, train_mae: 0.3197, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2499it [08:47,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500 — train_loss: 0.2189, train_mae: 0.3197, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2501it [09:36, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 2500 — train_loss: 0.2189, train_mae: 0.3197, val_loss: 0.2162, val_mae: 0.3215\n",
      "--------No significant MAE improvement for 500 iterations--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2601it [09:51,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2600 — train_loss: 0.2188, train_mae: 0.3195, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2701it [10:07,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2700 — train_loss: 0.2185, train_mae: 0.3193, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2801it [10:22,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2800 — train_loss: 0.2185, train_mae: 0.3194, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2901it [10:38,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2900 — train_loss: 0.2184, train_mae: 0.3193, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2999it [10:54,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000 — train_loss: 0.2184, train_mae: 0.3192, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3001it [11:44, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 3000 — train_loss: 0.2184, train_mae: 0.3192, val_loss: 0.2163, val_mae: 0.3118\n",
      "--------No significant MAE improvement for 1000 iterations--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3101it [12:00,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3100 — train_loss: 0.2183, train_mae: 0.3191, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3201it [12:17,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3200 — train_loss: 0.2183, train_mae: 0.3190, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3301it [12:35,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3300 — train_loss: 0.2183, train_mae: 0.3191, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3401it [12:51,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3400 — train_loss: 0.2184, train_mae: 0.3191, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3499it [13:07,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3500 — train_loss: 0.2183, train_mae: 0.3192, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3501it [13:57, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating! Step 3500 — train_loss: 0.2183, train_mae: 0.3192, val_loss: 0.2160, val_mae: 0.3187\n",
      "--------No significant MAE improvement for 1500 iterations--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3601it [14:14,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3600 — train_loss: 0.2184, train_mae: 0.3193, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3701it [14:30,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3700 — train_loss: 0.2184, train_mae: 0.3193, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3801it [14:47,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3800 — train_loss: 0.2183, train_mae: 0.3192, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3901it [15:04,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3900 — train_loss: 0.2183, train_mae: 0.3193, current_LR: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3979it [15:17,  6.23it/s]"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_val_mae = float('inf')\n",
    "num_iterations = 0\n",
    "patience_counter = 0    # Count iterations without sufficient improvement\n",
    "PATIENCE = 15000        # How many iterations to wait, noting that total_iters is around 117k for 3 epochs and batch size of 256\n",
    "MIN_IMPROVEMENT = 5e-4  # Minimum improvement required for early stopping to not trigger\n",
    "VAL_ITERS = 500\n",
    "LOG_ITERS = 100\n",
    "\n",
    "early_stop = False\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    if early_stop:\n",
    "        break\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_mae = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()   \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        batch_mae = torch.mean(torch.abs(preds - labels)).item()\n",
    "\n",
    "        total_loss += batch_loss * inputs.size(0)\n",
    "        total_mae += batch_mae * inputs.size(0)\n",
    "        num_iterations += 1\n",
    "\n",
    "        # Every 1000 steps, log training loss and MAE\n",
    "        if num_iterations % LOG_ITERS == 0:\n",
    "            avg_train_loss = total_loss / (num_iterations * train_loader.batch_size)\n",
    "            avg_train_mae = total_mae / (num_iterations * train_loader.batch_size)\n",
    "            print(f\"Step {num_iterations} — train_loss: {avg_train_loss:.4f}, train_mae: {avg_train_mae:.4f}, current_LR: {scheduler.get_last_lr()[0]:.4f}\")\n",
    "\n",
    "        # Every 5000 steps, run validation and record performance\n",
    "        if num_iterations % VAL_ITERS == 0:\n",
    "            model.eval()\n",
    "            val_loss_sum = 0.0\n",
    "            val_mae_sum = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    val_inputs, val_labels = val_inputs.to(DEVICE), val_labels.to(DEVICE)\n",
    "                    val_pred = model(val_inputs)\n",
    "                    val_loss = criterion(val_pred, val_labels)\n",
    "                    val_mae = torch.mean(torch.abs(val_pred - val_labels))\n",
    "\n",
    "                    val_loss_sum += val_loss.item() * val_inputs.size(0)\n",
    "                    val_mae_sum += val_mae.item() * val_inputs.size(0)\n",
    "\n",
    "            avg_val_loss = val_loss_sum / 250_000\n",
    "            avg_val_mae = val_mae_sum / 250_000\n",
    "\n",
    "            print(f\"Validating! Step {num_iterations} — train_loss: {avg_train_loss:.4f}, train_mae: {avg_train_mae:.4f}, val_loss: {avg_val_loss:.4f}, val_mae: {avg_val_mae:.4f}\")\n",
    "\n",
    "            steps.append(num_iterations)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            train_maes.append(avg_train_mae)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_maes.append(avg_val_mae)\n",
    "\n",
    "            # Checkpoint best\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"best_chess_transformer.pth\")\n",
    "                print(f\"Saved new best model after {num_iterations} iters\")\n",
    "            \n",
    "            # Check if validation MAE improved enough\n",
    "            if avg_val_mae + MIN_IMPROVEMENT < best_val_mae:\n",
    "                best_val_mae = avg_val_mae\n",
    "                patience_counter = 0  # Reset patience\n",
    "                print(f\"--------Validation MAE improved to {best_val_mae:.6f}--------\")\n",
    "            else:\n",
    "                patience_counter += VAL_ITERS  # because we validate after every VAL_ITERS \n",
    "                print(f\"--------No significant MAE improvement for {patience_counter} iterations--------\")\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"Early stopping at {num_iterations} iterations (no significant MAE improvement)\")\n",
    "                early_stop = True\n",
    "                break\n",
    "\n",
    "            model.train() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
